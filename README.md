[合集 - 技术札纪——有限硬件与无限计算的权衡艺术(42)](https://github.com)

[1.书本介绍：技术札纪——有限硬件与无限计算的权衡艺术07-24](https://github.com/poemyang/p/19002322)[2.书本大纲：从芯片、分布式到云计算AI时代07-25](https://github.com/poemyang/p/19004265)[3.我的代码背叛了我？为什么 a=1, b=2，最后x和y都等于0？07-25](https://github.com/poemyang/p/19004704)[4.我的代码出现幻觉？说好的a = 1； x = b，怎么成了x = b； a = 1？07-28](https://github.com/poemyang/p/19008983)[5.为什么i++不是原子操作？一个让无数并发程序崩溃的“常识”07-29](https://github.com/poemyang/p/19010948)[6.没有Happens-Before？你的多线程代码就是‘一锅粥’！07-30](https://github.com/poemyang/p/19012883)[7.Hello World背后藏着什么秘密？一行代码看懂Java的“跨平台”魔法07-31](https://github.com/poemyang/p/19014740)[8.a+b=c，处理器一步搞定，Java虚拟机为啥要四步？08-01](https://github.com/poemyang/p/19016482)[9.“同声传译”还是“全文翻译”？为何HotSpot虚拟机仍要保留解释器？08-04](https://github.com/poemyang/p/19020937)[10.“代码跑着跑着，就变快了？”——揭秘Java性能幕后引擎：即时编译器08-05](https://github.com/poemyang/p/19022518)[11.Java编译器优化秘籍：字节码背后的IR魔法与常见技巧08-06](https://github.com/poemyang/p/19024509)[12.解锁硬件潜能：Java向量化计算，性能飙升W倍！08-07](https://github.com/poemyang/p/19026352)[13.new出来的对象，不一定在堆上？聊聊Java虚拟机的优化技术：逃逸分析08-08](https://github.com/poemyang/p/19027777)[14.性能优化之母：为什么说“方法内联”是编译器优化中最关键的一步棋？08-11](https://github.com/poemyang/p/19031406)[15.从纳秒到毫秒的“时空之旅”：CPU是如何看待内存与硬盘的？08-12](https://github.com/poemyang/p/19033086)[16.硬盘性能提升100倍的秘密：看懂顺序I/O的魔力08-14](https://github.com/poemyang/p/19038725)[17.十年大厂员工终明白：MySQL性能优化的尽头，是对B+树的极致理解08-18](https://github.com/poemyang/p/19043960)[18.Facebook内部都在用的存储引擎，LSM凭什么能硬扛亿级写入流量？08-21](https://github.com/poemyang/p/19050442)[19.千亿消息“过眼云烟”？Kafka把硬盘当内存用的性能魔法，全靠这一手！08-22](https://github.com/poemyang/p/19052513)[20.RPC的三大问题：跨语言、跨平台通信的终极解决方案是如何炼成的？08-27](https://github.com/poemyang/p/19060527)[21.从文本到二进制：HTTP/2不止于性能，更是对HTTP/1核心语义的传承与革新08-28](https://github.com/poemyang/p/19061836):[闪电加速器](https://politicalagenda.org)[22.从HPACK到多路复用，揭秘HTTP/2如何终结网络拥堵08-29](https://github.com/poemyang/p/19063734)[23.站在巨人的肩膀上：gRPC通过HTTP/2构建云原生时代的通信标准09-01](https://github.com/poemyang/p/19068100)[24.gRPC不是银弹：为内网极致性能，如何设计自己的RPC协议？09-03](https://github.com/poemyang/p/19071487)[25.从JSON到Protobuf，深入序列化方案的选型与原理09-04](https://github.com/poemyang/p/19073206)[26.“卧槽，系统又崩了！”——别慌，这也许是你看过最通俗易懂的分布式入门09-05](https://github.com/poemyang/p/19074847)[27.海量数据如何“安家”？一文读懂哈希、范围和一致性哈希三大分片策略09-08](https://github.com/poemyang/p/19079520)[28.“你还活着吗？” “我没死，只是网卡了！”——来自分布式世界的“生死契约”09-09](https://github.com/poemyang/p/19082361)[29.“凭什么说你比我先？”——没有上帝时钟，如何判断“谁先谁后”？09-12](https://github.com/poemyang/p/19087563)[30.“鸡蛋不能放一个篮子里”，如何确保千亿数据万无一失？09-15](https://github.com/poemyang/p/19092154)[31.系统里数据又“打架”了？让“少数服从多数”来终结这场混乱！09-18](https://github.com/poemyang/p/19097975)[32.技术圈的“绯闻女孩”：Gossip是如何把八卦秘密传遍全网的？09-19](https://github.com/poemyang/p/19100196)[33.绯闻女孩不只会八卦：从“验明正身”到“抓内鬼”，Gossip的进阶玩法09-20](https://github.com/poemyang/p/19101931)[34.从混沌到秩序：Java共享内存模型如何通过显式约束驯服并发？09-23](https://github.com/poemyang/p/19106679)[35.一把锁的两种承诺：synchronized如何同时保证互斥与内存可见性？09-24](https://github.com/poemyang/p/19108676)[36.从MESA模型到锁升级：synchronized性能逆袭的底层逻辑09-25](https://github.com/poemyang/p/19110705)[37.揭秘JUC：volatile与CAS，并发编程的两大基石09-27](https://github.com/poemyang/p/19114881)[38.“不要通过共享内存来通信”——深入理解Golang并发模型与CSP理论10-13](https://github.com/poemyang/p/19139419)[39.Goroutine间的“灵魂管道”：Channel如何实现数据同步与因果传递？10-14](https://github.com/poemyang/p/19142146)[40.“一切皆文件”：揭秘LINUX I/O与虚拟内存的底层设计哲学10-15](https://github.com/poemyang/p/19143895)[41.你的程序为何卡顿？从LINUX I/O三大模式寻找答案10-16](https://github.com/poemyang/p/19146666)

42.单线程如何撑起百万连接？I/O多路复用：现代网络架构的基石10-17

收起

I/O多路复用（I/O Multiplexing）是一种允许单个线程同时监视多个文件描述符的I/O模型。其核心价值在于，它将应用程序从低效的I/O等待中解放出来，实现了“一次等待，响应多个事件”的高效并发模式。
要理解其优势，需要对比非阻塞I/O的局限性。虽然非阻塞I/O能避免线程在数据未就绪时阻塞，但它要求应用程序通过循环不断地主动轮询所有文件描述符，这会造成大量的处理器空转，浪费计算资源。
I/O多路复用则提供了一种优雅的解决方案：应用程序将监视任务委托给内核，然后阻塞在专门的事件等待调用上（如select, epoll\_wait）。只有当一个或多个文件描述符就绪时，内核才会唤醒线程，使其仅对活跃的I/O进行处理。这是一种从“主动轮询”到“被动通知”的转变，极大地提升了系统效率。

![image](https://img2024.cnblogs.com/blog/757914/202510/757914-20251017203636634-653099140.png)

I/O多路复用技术本身也经历了一场深刻的演进，从select、poll到epoll，其效率和设计哲学不断完善。作为早期的POSIX标准，select和poll引入了核心理念，但存在固有的性能缺陷。它们要求应用程序在每次调用时，都将整个待监视的文件描述符集合从用户空间完整地拷贝到内核空间，操作完成后再拷贝回来。更关键的是，内核需要以O(n)的线性复杂度遍历所有文件描述符来检查其状态，这意味着随着连接数的增长，系统开销会显著增加。此外，select还受限于FD\_SETSIZE（通常为1024）的硬性数量限制，而poll虽解除了此限制，但并未改变其低效的内核扫描和数据拷贝机制。
真正的技术飞跃在Linux平台上以epoll的形式出现。epoll彻底重构了接口和内核实现，它通过epoll\_create在内核中建立一个持久化的事件中心，应用程序只需通过epoll\_ctl将文件描述符注册一次，后续便无需重复提交。其内部采用红黑树来高效管理文件描述符，并利用设备驱动的回调机制，在I/O就绪时主动将FD添加到一个“就绪队列”中。
因此，当应用程序调用epoll\_wait时，内核只需返回这个就绪队列的内容，其时间复杂度为O(k)（k为活跃连接数），与被监视的文件描述符总数无关。这种设计不仅避免了无谓的数据拷贝，更将内核的查找效率提升到了极致。

![image](https://img2024.cnblogs.com/blog/757914/202510/757914-20251017203644831-2101597118.png)

此外，epoll还提供了水平触发（Level-Triggered, LT）和边缘触发（Edge-Triggered, ET）两种工作模式。LT模式是默认选项，只要缓冲区中存在数据，每次调用epoll\_wait都会触发通知，编程模型更简单、容错性高。而ET模式则仅在FD状态发生变化（如数据从无到有）时通知一次，它要求应用程序必须一次性处理完所有数据，虽然编程复杂度更高，但能有效减少系统调用的次数。
从本质上看，I/O多路复用仍属于同步I/O，因为应用程序在调用epoll\_wait时是阻塞的。但它的阻塞点是高效的事件等待，而非低效的I/O操作。
这种模型天然地催生了事件循环（Event Loop）这一经典并发模式。一个或少数几个事件循环线程负责等待I/O事件，并将就绪的任务分发给工作者线程池（Worker Threads）处理，实现了I/O操作与业务逻辑的解耦。这种流水线式的处理方式，可以充分利用多核处理器，进一步提升系统吞吐量。
以下伪代码展示了基于epoll的事件循环流程：

```
// 伪代码: I/O多路复用 (epoll)
epoll_fd = epoll_create();
// 1. 创建epoll实例
epoll_fd = epoll_create();

// 2. 注册关心的文件描述符和事件
epoll_ctl(epoll_fd, ADD, socket1, READ_EVENT);
epoll_ctl(epoll_fd, ADD, socket2, READ_EVENT);

// 3. 进入事件循环
while (true) {
    // 阻塞等待，直到有事件发生，仅返回就绪的事件列表
    ready_events = epoll_wait(epoll_fd); 
    
    // 4. 处理所有就绪的事件
    for (event in ready_events) {
        if (event.is_readable()) {
            data = read(event.fd); // 此处read通常不会阻塞
            process(data);         // 交给业务逻辑处理
        }
    }
}
```

**未完待续**

**很高兴与你相遇！如果你喜欢本文内容，记得关注哦**
